{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optuna and w&b setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb_kwargs = {\"project\": \"FINDING_BEST_COMBINATION_GUNJAN\"}\n",
    "# wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs, as_multirun=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = pickle.load(\n",
    "    open(\"./MIT_split/train_images_filenames.dat\", \"rb\")\n",
    ")\n",
    "test_images_filenames = pickle.load(open(\"./MIT_split/test_images_filenames.dat\", \"rb\"))\n",
    "train_images_filenames = [\".\" + n[15:] for n in train_images_filenames]\n",
    "test_images_filenames = [\".\" + n[15:] for n in test_images_filenames]\n",
    "train_labels = pickle.load(open(\"./MIT_split/train_labels.dat\", \"rb\"))\n",
    "test_labels = pickle.load(open(\"./MIT_split/test_labels.dat\", \"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIFT_des(img: np.array, pixel_interval: int = None):\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # dense representation based on pixel interval\n",
    "    if pixel_interval is not None:\n",
    "        keypoints = [\n",
    "            cv2.KeyPoint(x, y, pixel_interval)\n",
    "            for y in range(0, img.shape[0], pixel_interval)\n",
    "            for x in range(0, img.shape[1], pixel_interval)\n",
    "        ]\n",
    "        _, descriptors = sift.compute(img, keypoints)\n",
    "    # regular keypoint representation\n",
    "    else:\n",
    "        keypoints = sift.detect(img, None)\n",
    "        _, descriptors = sift.compute(img, keypoints)\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def ORB_des(img, pixel_interval: int = None):\n",
    "    orb = cv2.ORB_create()\n",
    "    if pixel_interval is not None:\n",
    "        keypoints = [\n",
    "            cv2.KeyPoint(x, y, pixel_interval)\n",
    "            for y in range(0, img.shape[0], pixel_interval)\n",
    "            for x in range(0, img.shape[1], pixel_interval)\n",
    "        ]\n",
    "        _, descriptors = orb.compute(img, keypoints)\n",
    "    else:\n",
    "        keypoints = orb.detect(img, None)\n",
    "        _, descriptors = orb.compute(img, keypoints)\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def FAST_des(img, pixel_interval: int = None):\n",
    "    fast = cv2.FastFeatureDetector_create()\n",
    "\n",
    "    if pixel_interval is not None:\n",
    "        keypoints = [\n",
    "            cv2.KeyPoint(x, y, pixel_interval)\n",
    "            for y in range(0, img.shape[0], pixel_interval)\n",
    "            for x in range(0, img.shape[1], pixel_interval)\n",
    "        ]\n",
    "    else:\n",
    "        keypoints = fast.detect(img, None)\n",
    "\n",
    "    # Compute descriptors using ORB\n",
    "    orb = cv2.ORB_create()\n",
    "    _, descriptors = orb.compute(img, keypoints)\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def get_descriptor_feature(\n",
    "    img: np.array, descriptor_name: str, pixel_interval: int = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper function: Compute and return the descriptors for the given image using the specified feature detection algorithm.\n",
    "\n",
    "    Args:\n",
    "        img (np.array): input image \n",
    "\n",
    "        descriptor_name (str): Name of the descriptor algorithm \n",
    "\n",
    "        pixel_interval (int, optional): The interval at which keypoints are sampled in the image. If provided,\n",
    "                                        keypoints are generated at regular intervals over the image based on this value.\n",
    "                                        If None, the algorithm will automatically determine the keypoints. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        _type_: Returns a numpy array of descriptors. The type and structure of the array depend on the chosen descriptor algorithm.\n",
    "                - If \"SIFT\" is chosen, SIFT descriptors are returned.\n",
    "                - If \"ORB\" is chosen, ORB descriptors are returned.\n",
    "                - If \"FAST\" is chosen, descriptors are computed using the FAST algorithm for keypoint detection and ORB for descriptor computation.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If an unsupported descriptor name is provided, the function raises an assertion error.\n",
    "    \"\"\"\n",
    "    if descriptor_name == \"SIFT\":\n",
    "        return SIFT_des(img, pixel_interval)\n",
    "    elif descriptor_name == \"ORB\":\n",
    "        return ORB_des(img, pixel_interval)\n",
    "    elif descriptor_name == \"FAST\":\n",
    "        return FAST_des(img, pixel_interval)\n",
    "    else:\n",
    "        assert False, f\"{descriptor_name} is not supported !!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# norm scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_feature(feature:np.array)->np.array:\n",
    "    \"\"\"\n",
    "    Helper function to scale the provided feature using standard scaling.\n",
    "\n",
    "\n",
    "\n",
    "    Args:\n",
    "        feature(np.array): A feature array\n",
    "\n",
    "    Returns:\n",
    "        scaled_feature(np.array): The scaled version of the input feature. This is a NumPy array where each\n",
    "                        feature is scaled to have zero mean and unit variance.\n",
    "    \"\"\"\n",
    "    # Create a StandardScaler object\n",
    "    scaler = (\n",
    "        StandardScaler()\n",
    "    ) \n",
    "\n",
    "    # apply scaler transform\n",
    "    scaled_feature = scaler.fit_transform(feature)\n",
    "    return scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimensionality reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "def dim_reduction(method: str, train_X: list, train_y: list = None):\n",
    "    \"\"\"\n",
    "    Helper function to perform dimensionality reduction on the input data\n",
    "\n",
    "\n",
    "    Args:\n",
    "        method (str): method to be used for dimensionality reduction. Supported values are \"PCA\" and \"LDA\".\n",
    "\n",
    "        train_X (list):  training data features\n",
    "        train_y (list, optional): training data labels, required for LDA.\n",
    "\n",
    "    Returns:\n",
    "        model: The dimensionality reduction model after being fit to the data.\n",
    "               - If \"PCA\" is chosen, a PCA model is returned.\n",
    "               - If \"LDA\" is chosen, an LDA model is returned.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If an unsupported method is provided or if train_y is None when using LDA.\n",
    "    \"\"\"\n",
    "    if method == \"PCA\":\n",
    "        # Apply PCA for dimensionality reduction\n",
    "        pca = PCA(n_components=64)\n",
    "        train_X = pca.fit_transform(train_X)\n",
    "        return pca\n",
    "\n",
    "    elif method == \"LDA\":\n",
    "        # Apply LDA for dimensionality reduction, requires train_y labels\n",
    "        if train_y is not None:\n",
    "            lda = LinearDiscriminantAnalysis(n_components=7)\n",
    "            train_X = lda.fit_transform(train_X, train_y)\n",
    "        else:\n",
    "            assert False, \"train_y cannot be None for LDA\"\n",
    "        return lda\n",
    "\n",
    "    else:\n",
    "        assert (\n",
    "            False\n",
    "        ), f\"{method} is not supported as a dimensionality reduction method!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag of visual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "\n",
    "def create_bag_visual_word(\n",
    "    train_images_filenames,\n",
    "    descriptor_name,\n",
    "    pixel_interval,\n",
    "    k: int,\n",
    "    apply_Scaling: bool,\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to create a bag of visual words model using the specified feature descriptors from training images.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        train_images_filenames: A list of filenames of the training images.\n",
    "\n",
    "        descriptor_name: name of the descriptor algorithm to be used for feature extraction.\n",
    "\n",
    "        pixel_interval: pixel interval at which keypoints are sampled in the image for feature extraction.\n",
    "\n",
    "        k (int): number of clusters to use in k-means. This defines the size of the visual vocabulary.\n",
    "\n",
    "        apply_Scaling (bool): flag to determine whether to scale the features before clustering.\n",
    "\n",
    "    Returns:\n",
    "        codebook: A trained MiniBatchKMeans object that represents the bag of visual words model.\n",
    "                 \n",
    "    \"\"\"\n",
    "    feature_stack = []\n",
    "\n",
    "    # Loop through each image, extract features, and optionally scale them\n",
    "    for file in tqdm(train_images_filenames):\n",
    "        img = cv2.imread(file)\n",
    "        feature = get_descriptor_feature(\n",
    "            img=img, descriptor_name=descriptor_name, pixel_interval=pixel_interval\n",
    "        )\n",
    "        if apply_Scaling:\n",
    "            feature = get_scaled_feature(feature)\n",
    "        feature_stack.append(feature)\n",
    "\n",
    "    # Stack all features into a single numpy array\n",
    "    D = np.vstack(feature_stack)\n",
    "\n",
    "    # Use MiniBatchKMeans for clustering the features to create the visual words\n",
    "    codebook = MiniBatchKMeans(\n",
    "        n_clusters=k,\n",
    "        verbose=False,\n",
    "        batch_size=k * 20,\n",
    "        compute_labels=False,\n",
    "        reassignment_ratio=10**-4,\n",
    "        random_state=42,\n",
    "        n_init=\"auto\",\n",
    "    )\n",
    "    codebook.fit(D)\n",
    "\n",
    "    return codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_histogram(features, codebook):\n",
    "    \"\"\"\n",
    "    Calculate the histogram for any feature vector using a pre-trained visual vocabulary (codebook).\n",
    "\n",
    "    Args:\n",
    "        features: Calculated keypoints' descriptor (2D array where each row is a descriptor).\n",
    "        codebook: Pre-trained visual vocabulary (MiniBatchKMeans object).\n",
    "\n",
    "    Returns:\n",
    "        Histogram of visual word occurrences.\n",
    "    \"\"\"\n",
    "    words = codebook.predict(features)\n",
    "    histogram = np.bincount(words, minlength=codebook.n_clusters)\n",
    "    histogram = histogram.astype(np.float32)\n",
    "    histogram /= histogram.sum()  # Normalize the histogram\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spatial pyramid technique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_pyramid_local_feature_extractor(\n",
    "    image: np.array,\n",
    "    descriptor_name: str,\n",
    "    visual_vocabulary: np.array,\n",
    "    pixel_interval: int,\n",
    "    apply_Scaling: bool,\n",
    "    max_level: int = 2,\n",
    "):\n",
    "    \"\"\"\n",
    "    WE WILL USE 2 LEVEL\n",
    "    LEVEL 0: COMPLETE IMAGE\n",
    "    LEVEL 1: 2X2 GRID\n",
    "    LEVEL 2: 4X4 GRID\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    final_feature_vector = []\n",
    "\n",
    "    for level in range(max_level + 1):\n",
    "        # NUMBER OF DIVISION\n",
    "        divisions = 2**level\n",
    "\n",
    "        region_height = height // divisions\n",
    "        region_width = width // divisions\n",
    "\n",
    "        for i in range(divisions):\n",
    "            for j in range(divisions):\n",
    "                start_x, start_y = i * region_width, j * region_height\n",
    "                end_x, end_y = start_x + region_width, start_y + region_height\n",
    "                region = image[start_y:end_y, start_x:end_x]\n",
    "\n",
    "                local_features = get_descriptor_feature(\n",
    "                    img=region,\n",
    "                    descriptor_name=descriptor_name,\n",
    "                    pixel_interval=pixel_interval,\n",
    "                )\n",
    "                if apply_Scaling:\n",
    "                    local_features = get_scaled_feature(feature=local_features)\n",
    "                try:\n",
    "                    histogram = compute_feature_histogram(\n",
    "                        local_features, visual_vocabulary\n",
    "                    )\n",
    "\n",
    "                    # TODO: LEVEL WISE WEIGHTED HISTOGRAM\n",
    "                    final_feature_vector.extend(histogram)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    # Normalize final feature vector\n",
    "    final_feature_vector = np.array(final_feature_vector)\n",
    "    final_feature_vector = final_feature_vector / np.linalg.norm(final_feature_vector)\n",
    "    return final_feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fisher vector technique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fisher_vector(\n",
    "    img: np.array, descriptor_name: str, pixel_interval: int, num_components: int\n",
    "):\n",
    "    descriptors = get_descriptor_feature(\n",
    "        img=img, descriptor_name=descriptor_name, pixel_interval=pixel_interval\n",
    "    )\n",
    "    gmm = GaussianMixture(n_components=num_components, covariance_type=\"diag\")\n",
    "    gmm.fit(descriptors)\n",
    "    n_kernels = gmm.n_components\n",
    "    descriptor_dim = descriptors.shape[1]\n",
    "\n",
    "    # Initialize Fisher Vector\n",
    "    fisher_vector = np.zeros(2 * descriptor_dim * n_kernels)\n",
    "\n",
    "    # Compute posterior probabilities (responsibilities) for each GMM component\n",
    "    probs = gmm.predict_proba(descriptors)\n",
    "\n",
    "    # Compute the sufficient statistics\n",
    "    for i in range(n_kernels):\n",
    "        # probability for each feature under component i\n",
    "        prob = probs[:, i].reshape(-1, 1)\n",
    "\n",
    "        # mean and covariance for component i\n",
    "        mean_i = gmm.means_[i]\n",
    "        covar_i = gmm.covariances_[i]  # Fixed line\n",
    "\n",
    "        # gradients with respect to the means\n",
    "        grad_mean = (descriptors - mean_i) / covar_i\n",
    "        fisher_vector[i * descriptor_dim : (i + 1) * descriptor_dim] = np.sum(\n",
    "            prob * grad_mean, axis=0\n",
    "        )\n",
    "\n",
    "        # gradients with respect to the covariances\n",
    "        grad_covar = (((descriptors - mean_i) ** 2) / covar_i - 1) / np.sqrt(covar_i)\n",
    "        fisher_vector[\n",
    "            n_kernels * descriptor_dim\n",
    "            + i * descriptor_dim : n_kernels * descriptor_dim\n",
    "            + (i + 1) * descriptor_dim\n",
    "        ] = np.sum(prob * grad_covar, axis=0)\n",
    "\n",
    "    #  normalization \n",
    "    fisher_vector = np.sign(fisher_vector) * np.sqrt(np.abs(fisher_vector))\n",
    "    norm = np.sqrt(np.sum(fisher_vector**2))\n",
    "    if norm > 0:\n",
    "        fisher_vector /= norm\n",
    "\n",
    "    return fisher_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_intersection_kernel(X, Y):\n",
    "    return np.sum(np.minimum(X, Y), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svm(train_X, train_y, C=1.0, kernel=\"rbf\"):\n",
    "    if kernel == 'histinter':\n",
    "        svc = SVC(C=C, kernel=histogram_intersection_kernel)\n",
    "    else: \n",
    "        svc = SVC(C=C, kernel=kernel)\n",
    "    svc.fit(train_X, train_y)\n",
    "    return svc\n",
    "\n",
    "\n",
    "def fit_knn(train_X, train_y, n_neighbors=7, metric=\"euclidean\"):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, n_jobs=-1, metric=metric)\n",
    "    knn.fit(train_X, train_y)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier(train_X, train_y, classifier: str, **kwargs):\n",
    "\n",
    "\n",
    "    if classifier == \"KNN\":\n",
    "        n_neighbors = 7\n",
    "        if \"n_neighbors\" in kwargs:\n",
    "            n_neighbors = kwargs[\"n_neighbors\"]\n",
    "\n",
    "        metric = \"euclidean\"\n",
    "        if \"metric\" in kwargs:\n",
    "            metric = kwargs[\"metric\"]\n",
    "\n",
    "        return fit_knn(\n",
    "            train_X=train_X, train_y=train_y, n_neighbors=n_neighbors, metric=metric\n",
    "        )\n",
    "\n",
    "    if classifier == \"SVM\":\n",
    "        C = 1.0\n",
    "        if \"C\" in kwargs:\n",
    "            C = kwargs[\"C\"]\n",
    "\n",
    "        kernel = \"rbf\"\n",
    "        if \"kernel\" in kwargs:\n",
    "            kernel = kwargs[\"kernel\"]\n",
    "\n",
    "        return fit_svm(train_X=train_X, train_y=train_y, C=C, kernel=kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(\n",
    "    descriptor_name: str,  # Name of the feature descriptor to be used (e.g., SIFT, ORB)\n",
    "    training_method: str,  # Specifies the training method, e.g., SIMPLE_BOVW, SPATIAL_PYRAMID_BOVW, FISHER_VECTOR\n",
    "    pixel_interval: int,  # Interval for pixel sampling in image processing\n",
    "    train_images_filenames:List[str],  # List of filenames (paths) for the training images\n",
    "    train_labels:List[str],  # Corresponding labels for the training images\n",
    "    codebook,  # The visual vocabulary (codebook) for feature encoding\n",
    "    gmm_n_components: int,  # Number of components for the Gaussian Mixture Model (relevant for FISHER_VECTOR method)\n",
    "    apply_Scaling: bool,\n",
    "    classifier_model_name: str,\n",
    "    KNN_classifier_n_neighbor: int = None,\n",
    "    KNN_classifier_metrics: str = None,\n",
    "    SVM_classifier_c: int = None,\n",
    "    SVM_classifier_kernel: str = None,\n",
    "    dimensionality_reduction_technique: str = None,\n",
    "):\n",
    "    print(\"-\" * 10 + \"TRAINING FINAL CLASSIFICATION MODEL\" + \"-\" * 10)\n",
    "    # TRAIN DATA PREP\n",
    "    train_y = []\n",
    "    train_X = []\n",
    "\n",
    "    for file, label in tqdm(\n",
    "        zip(train_images_filenames, train_labels), total=len(train_images_filenames)\n",
    "    ):\n",
    "        img = cv2.imread(file)\n",
    "        if training_method == \"SIMPLE_BOVW\":\n",
    "            dst_features = get_descriptor_feature(\n",
    "                img=img, descriptor_name=descriptor_name, pixel_interval=pixel_interval\n",
    "            )\n",
    "\n",
    "            if apply_Scaling:\n",
    "                dst_features = get_scaled_feature(feature=dst_features)\n",
    "\n",
    "            features = compute_feature_histogram(\n",
    "                features=dst_features, codebook=codebook\n",
    "            )\n",
    "        elif training_method == \"SPATIAL_PYRAMID_BOVW\":\n",
    "            features = spatial_pyramid_local_feature_extractor(\n",
    "                image=img,\n",
    "                descriptor_name=descriptor_name,\n",
    "                visual_vocabulary=codebook,\n",
    "                pixel_interval=pixel_interval,\n",
    "                apply_Scaling=apply_Scaling,\n",
    "            )\n",
    "        elif training_method == \"FISHER\":\n",
    "            features = compute_fisher_vector(\n",
    "                img, descriptor_name, pixel_interval, num_components=gmm_n_components\n",
    "            )\n",
    "\n",
    "        train_X.append(features)\n",
    "        train_y.append(label)\n",
    "    # apply dimensionality reduction\n",
    "    if dimensionality_reduction_technique:\n",
    "        dim_reduction_model = dim_reduction(\n",
    "            method=dimensionality_reduction_technique, train_X=train_X, train_y=train_y\n",
    "        )\n",
    "        train_X = dim_reduction_model.transform(train_X)\n",
    "\n",
    "    else:\n",
    "        dim_reduction_model = None\n",
    "\n",
    "    # train classifier\n",
    "    classifier = get_classifier(\n",
    "        train_X=train_X,\n",
    "        train_y=train_y,\n",
    "        classifier=classifier_model_name,\n",
    "        n_neighbors=KNN_classifier_n_neighbor,\n",
    "        metric=KNN_classifier_metrics,\n",
    "        C=SVM_classifier_c,\n",
    "        kernel=SVM_classifier_kernel,\n",
    "    )\n",
    "    return classifier, dim_reduction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(\n",
    "    descriptor_name: str,\n",
    "    training_method: str,\n",
    "    pixel_interval,\n",
    "    codebook,\n",
    "    classifier,\n",
    "    gmm_n_components: int,\n",
    "    apply_Scaling: bool,\n",
    "    dim_reduction_model=None,\n",
    "    test_images_filenames: List[str] = test_images_filenames,\n",
    "    test_labels: List[str] = test_labels,\n",
    "):\n",
    "    print(\"-\" * 10 + \"CALCULATING FINAL CLASSIFICATION MODEL ACCURACY\" + \"-\" * 10)\n",
    "    test_y = []\n",
    "    test_X = []\n",
    "    if training_method == \"FISHER\":\n",
    "        pass\n",
    "\n",
    "    for file, label in tqdm(\n",
    "        zip(test_images_filenames, test_labels), total=len(test_images_filenames)\n",
    "    ):\n",
    "        img = cv2.imread(file)\n",
    "\n",
    "        if training_method == \"SIMPLE_BOVW\":\n",
    "            dst_features = get_descriptor_feature(\n",
    "                img=img, descriptor_name=descriptor_name, pixel_interval=pixel_interval\n",
    "            )\n",
    "\n",
    "            features = compute_feature_histogram(\n",
    "                features=dst_features, codebook=codebook\n",
    "            )\n",
    "            if apply_Scaling:\n",
    "                dst_features = get_scaled_feature(feature=dst_features)\n",
    "\n",
    "        elif training_method == \"SPATIAL_PYRAMID_BOVW\":\n",
    "            features = spatial_pyramid_local_feature_extractor(\n",
    "                image=img,\n",
    "                descriptor_name=descriptor_name,\n",
    "                visual_vocabulary=codebook,\n",
    "                pixel_interval=pixel_interval,\n",
    "                apply_Scaling=apply_Scaling,\n",
    "            )\n",
    "        elif training_method == \"FISHER\":\n",
    "            features = compute_fisher_vector(\n",
    "                img, descriptor_name, pixel_interval, num_components=gmm_n_components\n",
    "            )\n",
    "\n",
    "        test_X.append(features)\n",
    "        test_y.append(label)\n",
    "    if dim_reduction_model:\n",
    "        test_X = dim_reduction_model.transform(test_X)\n",
    "\n",
    "    pred_classes = classifier.predict(test_X)\n",
    "    # accuracy\n",
    "    accuracy = accuracy_score(test_y, pred_classes)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optuna hyper parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_descriptors = [\n",
    "    \"SIFT\",\n",
    "    \"ORB\",\n",
    "    \"FAST\",\n",
    "]\n",
    "available_training_method = [\"SIMPLE_BOVW\", \"SPATIAL_PYRAMID_BOVW\", \"FISHER\"]\n",
    "\n",
    "# TODO: implement t-SNE\n",
    "available_dimensionality_reduction_technique = [\"PCA\", \"LDA\", None]\n",
    "available_classifier_models = [\n",
    "    \"KNN\",\n",
    "    \"SVM\",\n",
    "]\n",
    "\n",
    "available_KNN_classifier_metrics = [\n",
    "    \"euclidean\",  # Euclidean distance\n",
    "    \"minkowski\",  # Minkowski distance, general form of Euclidean and Manhattan\n",
    "    \"chebyshev\",  # Chebyshev distance\n",
    "    \"hamming\",  # Hamming distance, for categorical variables\n",
    "    \"cosine\",  # Cosine similarity\n",
    "    \"jaccard\",  # Jaccard similarity\n",
    "]\n",
    "\n",
    "available_SVM_classifier_kernels = [\n",
    "    \"linear\",  # Linear kernel\n",
    "    \"poly\",  # Polynomial kernel\n",
    "    \"rbf\",  # Radial Basis Function (Gaussian) kernel\n",
    "    \"sigmoid\",  # Sigmoid kernel\n",
    "    \"histinter\", # Histogram intersection kernel\n",
    "]\n",
    "available_use_of_norm_scaler = [\"True\", \"False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trail):\n",
    "    wandb.init(project=\"FINDING_BEST_COMBINATION_GUNJAN\")\n",
    "\n",
    "    descriptor_name = trail.suggest_categorical(\n",
    "        \"descriptor_name\", available_descriptors\n",
    "    )\n",
    "\n",
    "    pixel_interval = trail.suggest_int(\"pixel_interval\", 5, 30)\n",
    "\n",
    "    training_method = trail.suggest_categorical(\n",
    "        \"training_method\", available_training_method\n",
    "    )\n",
    "\n",
    "    selected_classifier_model = trail.suggest_categorical(\n",
    "        \"classifier_model\", available_classifier_models\n",
    "    )\n",
    "    if selected_classifier_model == \"KNN\":\n",
    "        selected_KNN_classifier_n_neighbor = trail.suggest_int(\n",
    "            \"KNN_classifier_n_neighbor\", 5, 100\n",
    "        )\n",
    "        selected_KNN_classifier_metrics = trail.suggest_categorical(\n",
    "            \"KNN_classifier_metrics\", available_KNN_classifier_metrics\n",
    "        )\n",
    "\n",
    "        selected_SVM_classifier_c = None\n",
    "        selected_SVM_classifier_kernels = None\n",
    "\n",
    "    elif selected_classifier_model == \"SVM\":\n",
    "        selected_SVM_classifier_c = trail.suggest_int(\"SVM_classifier_c\", 1, 10)\n",
    "        selected_SVM_classifier_kernels = trail.suggest_categorical(\n",
    "            \"SVM_classifier_kernels\", available_SVM_classifier_kernels\n",
    "        )\n",
    "\n",
    "        selected_KNN_classifier_n_neighbor = None\n",
    "        selected_KNN_classifier_metrics = None\n",
    "\n",
    "    apply_Scaling = trail.suggest_categorical(\n",
    "        \"use_of_norm_scaler\", available_use_of_norm_scaler\n",
    "    )\n",
    "    apply_Scaling = eval(apply_Scaling)\n",
    "\n",
    "    selected_dimensionality_reduction_technique = trail.suggest_categorical(\n",
    "        \"dimensionality_reduction_technique\",\n",
    "        available_dimensionality_reduction_technique,\n",
    "    )\n",
    "    try:\n",
    "        if training_method in [\"SIMPLE_BOVW\", \"SPATIAL_PYRAMID_BOVW\"]:\n",
    "            bovw_num_cluster = trail.suggest_int(\"bovw_num_cluster\", 50, 1000)\n",
    "            codebook = create_bag_visual_word(\n",
    "                descriptor_name=descriptor_name,\n",
    "                k=bovw_num_cluster,\n",
    "                train_images_filenames=train_images_filenames,\n",
    "                pixel_interval=pixel_interval,\n",
    "                apply_Scaling=apply_Scaling,\n",
    "                dimensionality_reduction_technique=selected_dimensionality_reduction_technique,\n",
    "            )\n",
    "            gmm_n_components = None\n",
    "        elif training_method == \"FISHER\":\n",
    "            gmm_n_components = trail.suggest_int(\"gmm_n_components\", 10, 100)\n",
    "            codebook = None\n",
    "            bovw_num_cluster = None\n",
    "\n",
    "        classifier, dim_reduction_model = train_classifier(\n",
    "            descriptor_name=descriptor_name,\n",
    "            train_images_filenames=train_images_filenames,\n",
    "            training_method=training_method,\n",
    "            train_labels=train_labels,\n",
    "            codebook=codebook,\n",
    "            pixel_interval=pixel_interval,\n",
    "            gmm_n_components=gmm_n_components,\n",
    "            apply_Scaling=apply_Scaling,\n",
    "            classifier_model_name=selected_classifier_model,\n",
    "            KNN_classifier_n_neighbor=selected_KNN_classifier_n_neighbor,\n",
    "            KNN_classifier_metrics=selected_KNN_classifier_metrics,\n",
    "            SVM_classifier_c=selected_SVM_classifier_c,\n",
    "            SVM_classifier_kernel=selected_SVM_classifier_kernels,\n",
    "            dimensionality_reduction_technique=selected_dimensionality_reduction_technique,\n",
    "        )\n",
    "        accuracy = test_classifier(\n",
    "            descriptor_name=descriptor_name,\n",
    "            pixel_interval=pixel_interval,\n",
    "            training_method=training_method,\n",
    "            codebook=codebook,\n",
    "            classifier=classifier,\n",
    "            gmm_n_components=gmm_n_components,\n",
    "            apply_Scaling=apply_Scaling,\n",
    "            dim_reduction_model=dim_reduction_model,\n",
    "        )\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\">\" * 10 + \"ERROR\" + \"<\" * 10)\n",
    "        print(str(error))\n",
    "        print(\">\" * 10 + \"<\" * 10)\n",
    "        return 0\n",
    "\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"bovw_num_cluster\": bovw_num_cluster,\n",
    "            \"pixel_interval\": pixel_interval,\n",
    "            \"gmm_n_components\": gmm_n_components,\n",
    "            \"accuracy\": accuracy,\n",
    "        }\n",
    "    )\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     study = optuna.create_study(\n",
    "#         direction=\"maximize\",\n",
    "#         storage=\"sqlite:///db.sqlite3\",\n",
    "#         pruner=optuna.pruners.SuccessiveHalvingPruner(),\n",
    "#     )\n",
    "#     study.optimize(\n",
    "#         objective,\n",
    "#         n_trials=1000000000000000000,\n",
    "#         timeout=600000000000000000,\n",
    "#         callbacks=[wandbc], # weight and bias connection\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross validation with best parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST HYPER PARAMETERS\n",
    "bovw_num_cluster = 340\n",
    "descriptor_name = \"SIFT\"\n",
    "training_method = \"SIMPLE_BOVW\"\n",
    "pixel_interval = 5\n",
    "apply_Scaling = False\n",
    "classifier_model_name = \"SVM\"\n",
    "SVM_classifier_c = 1\n",
    "SVM_classifier_kernel = \"sigmoid\"\n",
    "dimensionality_reduction_technique = \"LDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1881/1881 [00:39<00:00, 47.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------TRAINING FINAL CLASSIFICATION MODEL----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1504/1504 [00:44<00:00, 33.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------CALCULATING FINAL CLASSIFICATION MODEL ACCURACY----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 377/377 [00:11<00:00, 32.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "accuracy: 0.8514588859416445\n",
      "####################################################################################################\n",
      "----------TRAINING FINAL CLASSIFICATION MODEL----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1505/1505 [00:47<00:00, 31.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------CALCULATING FINAL CLASSIFICATION MODEL ACCURACY----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 376/376 [00:12<00:00, 30.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "accuracy: 0.8191489361702128\n",
      "####################################################################################################\n",
      "----------TRAINING FINAL CLASSIFICATION MODEL----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1505/1505 [00:44<00:00, 33.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------CALCULATING FINAL CLASSIFICATION MODEL ACCURACY----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 376/376 [00:11<00:00, 33.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "accuracy: 0.824468085106383\n",
      "####################################################################################################\n",
      "----------TRAINING FINAL CLASSIFICATION MODEL----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1505/1505 [00:44<00:00, 33.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------CALCULATING FINAL CLASSIFICATION MODEL ACCURACY----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 376/376 [00:12<00:00, 29.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "accuracy: 0.8297872340425532\n",
      "####################################################################################################\n",
      "----------TRAINING FINAL CLASSIFICATION MODEL----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1505/1505 [00:45<00:00, 32.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------CALCULATING FINAL CLASSIFICATION MODEL ACCURACY----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 376/376 [00:11<00:00, 33.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "accuracy: 0.8218085106382979\n",
      "####################################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "performance_metrics = []\n",
    "bovw_num_cluster = bovw_num_cluster\n",
    "codebook = create_bag_visual_word(\n",
    "    descriptor_name=descriptor_name,\n",
    "    k=bovw_num_cluster,\n",
    "    train_images_filenames=train_images_filenames,\n",
    "    pixel_interval=pixel_interval,\n",
    "    apply_Scaling=apply_Scaling\n",
    ")\n",
    "for train_index, val_index in kfold.split(train_images_filenames):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train_files, X_val_files = [train_images_filenames[i] for i in train_index], [\n",
    "        train_images_filenames[i] for i in val_index\n",
    "    ]\n",
    "    y_train_labels, y_val_labels = [train_labels[i] for i in train_index], [\n",
    "        train_labels[i] for i in val_index\n",
    "    ]\n",
    "\n",
    "   \n",
    "\n",
    "    classifier, dim_reduction_model = train_classifier(\n",
    "        descriptor_name=descriptor_name,\n",
    "        train_images_filenames=X_train_files,\n",
    "        training_method=training_method,\n",
    "        train_labels=y_train_labels,\n",
    "        codebook=codebook,\n",
    "        pixel_interval=pixel_interval,\n",
    "        gmm_n_components=None,\n",
    "        apply_Scaling=apply_Scaling,\n",
    "        classifier_model_name=classifier_model_name,\n",
    "        # KNN_classifier_n_neighbor=selected_KNN_classifier_n_neighbor,\n",
    "        # KNN_classifier_metrics=selected_KNN_classifier_metrics,\n",
    "        SVM_classifier_c=SVM_classifier_c,\n",
    "        SVM_classifier_kernel=SVM_classifier_kernel,\n",
    "        dimensionality_reduction_technique=dimensionality_reduction_technique,\n",
    "    )\n",
    "    accuracy = test_classifier(\n",
    "        descriptor_name=descriptor_name,\n",
    "        pixel_interval=pixel_interval,\n",
    "        training_method=training_method,\n",
    "        codebook=codebook,\n",
    "        classifier=classifier,\n",
    "        gmm_n_components=None,\n",
    "        apply_Scaling=apply_Scaling,\n",
    "        dim_reduction_model=dim_reduction_model,\n",
    "        test_images_filenames=X_val_files,\n",
    "        test_labels=y_val_labels,\n",
    "    )\n",
    "    print(\"#\" * 100)\n",
    "    print(f\"accuracy: {accuracy}\")\n",
    "    print(\"#\" * 100)\n",
    "    performance_metrics.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Performance: 0.8293343303798182\n"
     ]
    }
   ],
   "source": [
    "# Average the results\n",
    "average_performance = sum(performance_metrics) / len(performance_metrics)\n",
    "print(f\"Average Performance: {average_performance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
